{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np1E33Yo340E"
      },
      "source": [
        "**Import librairies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSMmAUEjgmto",
        "outputId": "dddf7646-c3a5-4f20-9a7b-20b89137cbaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-lightning==1.9.4 in /usr/local/lib/python3.10/dist-packages (1.9.4)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.4) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.4) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.4) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.4) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.4) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.4) (1.1.2)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.4) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.4) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.4) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (3.8.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.4) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.4) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.4) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.4) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.4) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->pytorch-lightning==1.9.4) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->pytorch-lightning==1.9.4) (16.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->pytorch-lightning==1.9.4) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==1.9.4) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->pytorch-lightning==1.9.4) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install pytorch-lightning==1.9.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZpVl1723owB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CelebA\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_lightning import LightningModule\n",
        "from torch.nn import Conv2d, ConvTranspose2d, Flatten, Linear, LeakyReLU, Dropout, MaxPool2d, MSELoss, BatchNorm2d, ReLU, Tanh\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import torchvision.utils as vutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWsPMcivuTuO",
        "outputId": "f0c3a0b3-7e22-4352-8d55-d911843a42cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Seed:  999\n"
          ]
        }
      ],
      "source": [
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.use_deterministic_algorithms(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D-9yxVv37ZZ"
      },
      "source": [
        "**Load the dataset**\n",
        "\n",
        "Real-world images are taken from the [CelebA dataset](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bb1ihaYY6VD",
        "outputId": "163c2710-7e97-42c0-f317-b81288802a7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/img_align_celeba.zip\n",
            "replace img_align_celeba/000001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/img_align_celeba.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4j74NTDaGyD"
      },
      "outputs": [],
      "source": [
        "class CelebADataset(Dataset):\n",
        "  def __init__(self, root_dir):\n",
        "    self.img_names = os.listdir(root_dir)\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transforms.Compose([transforms.Resize(64),\n",
        "                                        transforms.CenterCrop(64),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_names)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.root_dir, self.img_names[idx])\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    img = self.transform(img)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSZvQsbE3_Aw"
      },
      "outputs": [],
      "source": [
        "dataset = CelebADataset('/content/img_align_celeba')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHyzCXPkqZK_"
      },
      "outputs": [],
      "source": [
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d00HyrIg4ASm"
      },
      "outputs": [],
      "source": [
        "img0 = dataset[0]\n",
        "print(img0.shape)\n",
        "plt.imshow(img0.permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MENVUom03-EO"
      },
      "source": [
        "**Generator**\n",
        "\n",
        "The task of the Generator is to create a fake image which is indistinguishable from a real image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_AF3rT3fXuG"
      },
      "outputs": [],
      "source": [
        "# GENERATOR ARCHITECTURE\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convT1 = ConvTranspose2d(in_channels=100, out_channels=512,\n",
        "                                      kernel_size=4, stride=1, padding=0)\n",
        "        self.norm1 = BatchNorm2d(512)\n",
        "        self.convT2 = ConvTranspose2d(in_channels=512, out_channels=256,\n",
        "                                      kernel_size=4, stride=2, padding=1)\n",
        "        self.norm2 = BatchNorm2d(256)\n",
        "        self.convT3 = ConvTranspose2d(in_channels=256, out_channels=128,\n",
        "                                      kernel_size=4, stride=2, padding=1)\n",
        "        self.norm3 = BatchNorm2d(128)\n",
        "        self.convT4 = ConvTranspose2d(in_channels=128, out_channels=64,\n",
        "                                      kernel_size=4, stride=2, padding=1)\n",
        "        self.norm4 = BatchNorm2d(64)\n",
        "        self.convT5 = ConvTranspose2d(in_channels=64, out_channels=3,\n",
        "                                      kernel_size=4, stride=2, padding=1)\n",
        "        self.relu = ReLU(inplace=True)\n",
        "        self.tanh = Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.relu(self.norm1(self.convT1(x)))\n",
        "        x2 = self.relu(self.norm2(self.convT2(x1)))\n",
        "        x3 = self.relu(self.norm3(self.convT3(x2)))\n",
        "        x4 = self.relu(self.norm4(self.convT4(x3)))\n",
        "        x5 = self.tanh(self.convT5(x4))\n",
        "        return x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkjjrSCNgzQZ"
      },
      "outputs": [],
      "source": [
        "gen = Generator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f_yMGcd3_QU"
      },
      "source": [
        "**Discriminator**\n",
        "\n",
        "The task of the Discriminator is to distinguish between 2 cases - real (from the domain) and fake images (generated)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSJqm0rBgyRb"
      },
      "outputs": [],
      "source": [
        "# DISCRIMINATOR ARCHITECTURE\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv2d(in_channels=3, out_channels=64, kernel_size=4,\n",
        "                            stride=2, padding=1, bias=False)\n",
        "        self.conv2 = Conv2d(in_channels=64, out_channels=128, kernel_size=4,\n",
        "                            stride=2, padding=1, bias=False)\n",
        "        self.norm2 = BatchNorm2d(128)\n",
        "        self.conv3 = Conv2d(in_channels=128, out_channels=256, kernel_size=4,\n",
        "                            stride=2, padding=1, bias=False)\n",
        "        self.norm3 = BatchNorm2d(256)\n",
        "        self.conv4 = Conv2d(in_channels=256, out_channels=512, kernel_size=4,\n",
        "                            stride=2, padding=1, bias=False)\n",
        "        self.norm4 = BatchNorm2d(512)\n",
        "        self.conv5 = Conv2d(in_channels=512, out_channels=1, kernel_size=4,\n",
        "                            stride=1, padding=0, bias=False)\n",
        "        self.l_relu = LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.l_relu(self.conv1(x))\n",
        "        x2 = self.l_relu(self.norm2(self.conv2(x1)))\n",
        "        x3 = self.l_relu(self.norm3(self.conv3(x2)))\n",
        "        x4 = self.l_relu(self.norm4(self.conv4(x3)))\n",
        "        pred = torch.sigmoid(self.conv5(x4))\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6cssJEEtTAA"
      },
      "outputs": [],
      "source": [
        "disc = Discriminator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zJf0KZk4AfG"
      },
      "source": [
        "**GAN Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE3fLJu64BOC"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "  def __init__(self, generator, discriminator):\n",
        "      self.generator = generator\n",
        "      self.generator.train()\n",
        "      self.discriminator = discriminator\n",
        "      self.discriminator.train()\n",
        "\n",
        "      # Loss function is Binary Cross Entropy between the target and the input probabilities\n",
        "      self.loss_fct = nn.BCELoss()\n",
        "\n",
        "      # Instantiate optimizer for the generator\n",
        "      self.generator_optim = optim.Adam(self.generator.parameters(),\n",
        "                                      lr=0.002,\n",
        "                                      betas=(0.5, 0.999))\n",
        "      # Instantiate optimizer for the discriminator\n",
        "      self.discriminator_optim = optim.Adam(self.discriminator.parameters(),\n",
        "                                          lr=0.002,\n",
        "                                          betas=(0.5, 0.999))\n",
        "\n",
        "  def train(self, train_dataset, epochs):\n",
        "      batch_counter = 0\n",
        "      batch_size = 50\n",
        "      latent_dim = 100 # for noise\n",
        "      disc_losses = []\n",
        "      gen_losses = []\n",
        "\n",
        "      for epoch in range(epochs):\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"epoch\", epoch)\n",
        "\n",
        "        self.discriminator_optim.zero_grad()\n",
        "        # Labels generated are soft labels:\n",
        "        # rather than being 1, they take values between 0.7 and 1.2\n",
        "        real_labels = (1.2 - 0.7) * torch.rand((batch_size,)) + 0.7\n",
        "        # rather than being 0, they take values between 0.3 and 0.0\n",
        "        fake_labels = (0.3 - 0.0) * torch.rand((batch_size,)) + 0.0\n",
        "        real_imgs = torch.empty((batch_size, 3, 64, 64))\n",
        "\n",
        "        # Update the Discriminator network:\n",
        "        # maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        for i in range(batch_size):\n",
        "          j = i + batch_counter\n",
        "          # Train with the batch of real images\n",
        "          real_imgs[i] = train_dataset[j].unsqueeze(0)\n",
        "        # Forward pass the batch of real images through the discriminator\n",
        "        output = self.discriminator(real_imgs).squeeze(3).squeeze(2).squeeze(1)\n",
        "        batch_counter += batch_size\n",
        "        # Calculate loss on real batch\n",
        "        real_discr_loss = self.loss_fct(output, real_labels)\n",
        "        # Calculate gradients for the real batch\n",
        "        real_discr_loss.backward(retain_graph=True)\n",
        "        # Get the D(x)\n",
        "        D_x = output.mean().item()\n",
        "        print(\"D(x): \", D_x)\n",
        "\n",
        "        # Train both the discriminator and generator with the fake batch\n",
        "        # Generate a batch of latent vectors\n",
        "        noise = torch.randn((batch_size, latent_dim, 1, 1))\n",
        "        # Generate fake images from noise\n",
        "        fake = self.generator(noise)\n",
        "        # Forward pass the batch of fake images through the discriminator\n",
        "        output = self.discriminator(fake).squeeze(3).squeeze(2).squeeze(1)\n",
        "        # Calculate loss on fake batch\n",
        "        fake_discr_loss = self.loss_fct(output, fake_labels)\n",
        "        # Calculate gradients for the fake batch\n",
        "        fake_discr_loss.backward(retain_graph=True)\n",
        "        # Get the D(G(z1))\n",
        "        D_G_z1 = fake_discr_loss.mean().item()\n",
        "        discr_loss = (real_discr_loss + fake_discr_loss)\n",
        "\n",
        "        # Update weights for the discriminator\n",
        "        self.discriminator_optim.step()\n",
        "\n",
        "        # Save losses for plotting\n",
        "        disc_losses.append(discr_loss.item())\n",
        "\n",
        "        print(\"epoch discr loss: \", discr_loss.item())\n",
        "\n",
        "        # Update the Generator network:\n",
        "        # maximize log(D(G(z)))\n",
        "        self.generator_optim.zero_grad()\n",
        "        # Forward pass the batch of fake images through the discriminator\n",
        "        output = self.discriminator(fake).squeeze(3).squeeze(2).squeeze(1)\n",
        "        # Calculate the generator's loss : here fake labels are interchanged with real labels\n",
        "        gen_loss = self.loss_fct(output, real_labels)\n",
        "        # Calculate gradients for the generator\n",
        "        gen_loss.backward(retain_graph=True)\n",
        "        # Get the D(G(z2))\n",
        "        D_G_z2 = output.mean().item()\n",
        "\n",
        "        print(\"D(G(x)): \", D_G_z1, \"/\", D_G_z2)\n",
        "\n",
        "        # Update the weights for the generator\n",
        "        self.generator_optim.step()\n",
        "\n",
        "        # Save losses for plotting\n",
        "        gen_losses.append(gen_loss.item())\n",
        "\n",
        "        print(\"epoch gen loss: \", gen_loss.item())\n",
        "\n",
        "      return disc_losses, gen_losses\n",
        "\n",
        "  def evaluate(self, test_dataset):\n",
        "        right_pred = 0\n",
        "        counter = 0\n",
        "        with torch.no_grad():\n",
        "            for i in range(6500, 7500):\n",
        "                input_real = test_dataset[i].unsqueeze(0)\n",
        "                output_real = self.discriminator(input_real)\n",
        "                if output_real.item() >= 0.5 : right_pred += 1\n",
        "\n",
        "                test_noise = torch.randn((1, 100, 1, 1))\n",
        "                input_fake = self.generator(test_noise)\n",
        "                output_fake = self.discriminator(input_fake)\n",
        "                if output_fake.item() < 0.5 : right_pred += 1\n",
        "        return right_pred/2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1XB-Or-Oetf"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(generator=gen,\n",
        "                  discriminator=disc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beyZCVAYOiuE"
      },
      "outputs": [],
      "source": [
        "nb_epochs = 250\n",
        "losses = trainer.train(dataset, nb_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc1v7vE7Epx2"
      },
      "outputs": [],
      "source": [
        "epoch_count = range(0, nb_epochs)\n",
        "D_losses = losses[0]\n",
        "plt.title('Evolution of the Discriminator loss')\n",
        "plt.plot(epoch_count, D_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X6VzOpdFCo5"
      },
      "outputs": [],
      "source": [
        "epoch_count = range(0, nb_epochs)\n",
        "G_losses = losses[1]\n",
        "plt.title('Evolution of the Generator loss')\n",
        "plt.plot(epoch_count, G_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uFXf2LJ4BYB"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxS8XE0Mo4C4"
      },
      "outputs": [],
      "source": [
        "avg_test_loss = trainer.evaluate(dataset)\n",
        "print(\"Average testing loss: \", avg_test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xzm2BvOszJS"
      },
      "source": [
        "Saving model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKFLJ82hs0OQ"
      },
      "outputs": [],
      "source": [
        "torch.save(disc.state_dict(), \"discriminator_260.pth\")\n",
        "torch.save(gen.state_dict(), \"generator_260.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb_ifMAXq4Dv"
      },
      "outputs": [],
      "source": [
        "one_latent = torch.rand((1, 100, 1, 1))\n",
        "rd0 = gen(one_latent).squeeze(0)\n",
        "print(rd0.shape)\n",
        "plt.imshow(rd0.permute(1, 2, 0).detach().numpy())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}